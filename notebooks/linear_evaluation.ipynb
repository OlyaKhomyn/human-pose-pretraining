{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fb45b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "import re\n",
    "import random\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# import nbimporter\n",
    "# from siamese import get_siam_net\n",
    "# from simclr import get_simclr_net\n",
    "\n",
    "\n",
    "class PanopticDataset(Dataset):\n",
    "    def __init__(self, transform):\n",
    "\n",
    "        self.data_path = \"/Users/olha/unitn/computer_vision/dataset/Panoptic/ProcessedPanopticDataset/\"\n",
    "#         self.data_path = '/media/mmlab/Volume/Panoptic/ProcessedPanopticDataset/'\n",
    "        self.training_dir = []\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "        paths = []\n",
    "\n",
    "        motion_seq = os.listdir(self.data_path)\n",
    "        no_dir = ['scripts','python','matlab','.git','glViewer.py','README.md','matlab',\n",
    "                'README_kinoptic.md']\n",
    "    \n",
    "        for dir in motion_seq:\n",
    "            if dir not in no_dir:\n",
    "                if 'haggling' in dir:\n",
    "                    continue\n",
    "                elif dir == '171204_pose2' or dir =='171204_pose5' or dir =='171026_cello3':\n",
    "                    if os.path.exists(os.path.join(self.data_path,dir,'hdJoints')):\n",
    "                        data_path = os.path.join(self.data_path,dir,'hdJoints')\n",
    "                        for lists in (os.listdir(data_path)):\n",
    "                            paths.append(os.path.join(data_path,lists.split('.json')[0]))\n",
    "                elif 'ian' in dir:\n",
    "                    continue\n",
    "                else:\n",
    "                    if os.path.exists(os.path.join(self.data_path,dir,'hdJoints')):\n",
    "                        data_path = os.path.join(self.data_path,dir,'hdJoints')\n",
    "                        for lists in (os.listdir(data_path)):\n",
    "                            paths.append(os.path.join(data_path,lists.split('.json')[0]))\n",
    "\n",
    "        self.data = {'paths': paths}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['paths'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        sample = dict()\n",
    "\n",
    "        path_split = self.data['paths'][idx].split('/hdJoints')\n",
    "        image_path = path_split[0] + '/hdImages' + path_split[-1] + '.jpg'\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        image =cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        sample['image'] = image\n",
    "        \n",
    "        joints_path = self.data['paths'][idx]+'.json'\n",
    "        \n",
    "        with open(joints_path) as dfile:\n",
    "            bframe = json.load(dfile)\n",
    "\n",
    "        sample['poses_2d'] = np.array(bframe['poses_2d'])\n",
    "        sample['poses_2d'] = torch.div(torch.tensor(sample['poses_2d'],dtype=torch.float), 224)\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71ffc15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this if you get an error\n",
    "# !pip3 install pytorch-lightning==1.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76e123aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Linear, self).__init__()\n",
    "        self.layers = nn.Sequential(nn.Linear(2048, 19 * 2))\n",
    " \n",
    "    def forward(self, x):\n",
    "        z = self.layers(x).sigmoid()\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d379cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_evaluation_model(path, base):\n",
    "    \n",
    "#     base.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
    "\n",
    "    base.load_state_dict(torch.load(path))\n",
    "    \n",
    "    base.fc = Linear()\n",
    "    \n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2ff689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "\n",
    "def get_optimizer(net, learning_rate, weight_decay, momentum):\n",
    "    final_layer_weights = []\n",
    "    rest_of_the_net_weights = []\n",
    "\n",
    "    for name, param in net.named_parameters():\n",
    "        if name.startswith('fc'):\n",
    "            final_layer_weights.append(param)\n",
    "        else:\n",
    "            param.requires_grad = False\n",
    "  \n",
    "    optimizer = SGD([\n",
    "        {'params': final_layer_weights, 'lr': learning_rate}\n",
    "    ], weight_decay=weight_decay, momentum=momentum)\n",
    "\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e436a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(batch_size):\n",
    "    \n",
    "    transforms = T.Compose(\n",
    "        [\n",
    "            T.ToTensor(),\n",
    "            T.Resize(size=(224, 224)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    data = PanopticDataset(transforms)\n",
    "    \n",
    "    num_samples = len(data)\n",
    "    \n",
    "    training_samples = int(num_samples * 0.6 + 1)\n",
    "    val_samples = int(num_samples * 0.2 + 1)\n",
    "    test_samples = num_samples - training_samples - val_samples\n",
    "    \n",
    "    training_data, val_data, test_data = torch.utils.data.random_split(\n",
    "        data, [training_samples, val_samples, test_samples]\n",
    "    )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(training_data, batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size, shuffle=False)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1099198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def training_step(net, data_loader, optimizer, cost_function, device='cuda'):\n",
    "    samples = 0.0\n",
    "    cumulative_loss = 0.0\n",
    "    cumulative_accuracy = 0.0\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    for batch_idx, batch in enumerate(tqdm(data_loader)):\n",
    "\n",
    "        images = batch['image']\n",
    "        poses = batch['poses_2d']\n",
    "        \n",
    "        images = images.to(device)\n",
    "        poses = poses.to(device)\n",
    "             \n",
    "        output = net(images)\n",
    "\n",
    "        loss = cost_function(output, poses)\n",
    "        cumulative_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        samples += images.shape[0]\n",
    "        \n",
    "        cumulative_accuracy += torch.cdist(output, poses, 2).mean()\n",
    "    \n",
    "    return cumulative_loss / samples, cumulative_accuracy / samples\n",
    "\n",
    "\n",
    "def test_step(net, data_loader, cost_function, device='cuda'):\n",
    "    samples = 0.\n",
    "    cumulative_loss = 0.\n",
    "    cumulative_accuracy = 0.\n",
    "\n",
    "    net.eval() \n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch_idx, batch in enumerate(tqdm(data_loader)):\n",
    "            images = batch['image']\n",
    "            poses = batch['poses_2d']\n",
    "        \n",
    "            images = images.to(device)\n",
    "            poses = poses.to(device)\n",
    "            \n",
    "            output = net(images)\n",
    "\n",
    "            loss = cost_function(output, poses)\n",
    "            cumulative_loss += loss.item()\n",
    "            \n",
    "            samples += images.shape[0]\n",
    "            cumulative_accuracy += torch.cdist(output, poses, 2).mean()\n",
    "  \n",
    "    return loss / samples, cumulative_accuracy / samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d644129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(path, base, batch_size=128, device='cuda', learning_rate=0.01, weight_decay=0.000001, momentum=0.9, epochs=20):\n",
    "    train_loader, val_loader, test_loader = get_data(batch_size)\n",
    "    \n",
    "    net = get_linear_evaluation_model(path, base).to(device)\n",
    "    \n",
    "    optimizer = get_optimizer(net, learning_rate, weight_decay, momentum)\n",
    "    \n",
    "    cost_function = nn.L1Loss(reduction='sum')\n",
    "    \n",
    "    for e in range(epochs):\n",
    "    \n",
    "        train_loss, train_accuracy = training_step(net, train_loader, optimizer, cost_function, device)\n",
    "        val_loss, val_accuracy = test_step(net, val_loader, cost_function, device)\n",
    "\n",
    "        print('Epoch: {:d}'.format(e+1))\n",
    "        print('\\tTraining loss {:.5f}, Training Acc {:.4f}'.format(train_loss, train_accuracy))\n",
    "        print('\\tValidation loss {:.5f}, Validation Acc {:.2f}'.format(val_loss, val_accuracy))\n",
    "        print('-----------------------------------------------------')\n",
    "\n",
    "        torch.save(net.state_dict(), 'sim_linear.pt')\n",
    "\n",
    "    print('After training:')\n",
    "    train_loss, train_accuracy = test_step(net, train_loader, cost_function, device)\n",
    "    val_loss, val_accuracy = test_step(net, val_loader, cost_function, device)\n",
    "    test_loss, test_accuracy = test_step(net, test_loader, cost_function, device)\n",
    "    \n",
    "    print('\\tTraining loss {:.5f}, Training MAP {:.4f}'.format(train_loss, train_accuracy))\n",
    "    print('\\tValidation loss {:.5f}, Validation MAP {:.4f}'.format(val_loss, val_accuracy))\n",
    "    print('\\tTest loss {:.5f}, Test MAP {:.4f}'.format(test_loss, test_accuracy))\n",
    "    print('-----------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53ba1b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29ac7ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simclr_path = '/Users/olha/unitn/computer_vision/lectures/ver0.pt'\n",
    "# siam_path = '/Users/olha/unitn/computer_vision/lectures/siam.pt'\n",
    "simclr_path = 'ver0.pt'\n",
    "\n",
    "# siam = get_siam_net()\n",
    "simclr = get_simclr_net()\n",
    "\n",
    "main(simclr_path, simclr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b4dfc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02168e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3f74fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1746df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd96cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3e44eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ef6dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc671f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe48edcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59eebd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
